<h1 align="center">âš¡ OptiFusion âš¡</h1>

<p align="center">SA â€¢ RL â€¢ FL â€” Hybrid Optimization Framework</p>

<p align="center">
  <img src="https://img.shields.io/badge/Optimization-Hybrid-blueviolet?style=flat-square" />
</p>

<hr/>




<p align="center">

<!-- Badges -->
<img src="https://img.shields.io/badge/Build-Stable-brightgreen?style=for-the-badge" />
<img src="https://img.shields.io/badge/Version-1.0.0-blue?style=for-the-badge" />
<img src="https://img.shields.io/badge/Datasets-Heart%20Disease%2C%20Heart%20Failure-orange?style=for-the-badge" />
<img src="https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge" />

</p>

---

## ğŸ“Œ Overview

**OptiFusion** combines three powerful optimization paradigms into a single machine learning framework:

- ğŸ”¥ **Simulated Annealing (SA)** â€” Global search & feature optimization  
- ğŸ§  **Reinforcement Learning (RL)** â€” Reward-driven configuration tuning  
- ğŸŒ **Federated Learning (FL)** â€” Distributed model training without data sharing  

This hybrid architecture delivers **robust**, **scalable**, and **high-performance** optimization suitable for ML tasks, currently applied to **heart disease prediction**.

> **Description:**  
> *OptiFusion combines multiple optimization strategiesâ€”SA, RL, and FLâ€”into a unified ML framework for efficient model and feature optimization.*

---

## ğŸ—ï¸ Architecture Highlights

âœ” Modular pipeline  
âœ” Independent + ensemble optimization modes  
âœ” Automatic metric evaluation  
âœ” Visualization-ready outputs  
âœ” Serialized models for reuse  
âœ” Dataset guides included  

---

## ğŸ“‚ Project Structure

```text
OptiFusion/
â”‚
â”œâ”€â”€ scripts/                         # Core modules
â”‚   â”œâ”€â”€ 01_data_processing.py
â”‚   â”œâ”€â”€ 02_simulated_annealing.py
â”‚   â”œâ”€â”€ 03_reinforcement_learning.py
â”‚   â”œâ”€â”€ 04_federated_learning.py
â”‚   â”œâ”€â”€ 05_evaluation_metrics.py
â”‚   â”œâ”€â”€ 06_visualizations.py
â”‚   â”œâ”€â”€ 07_main_orchestration.py
â”‚   â””â”€â”€ 08_ensemble_optimizer.py
â”‚
â”œâ”€â”€ output/                          # Results, models & plots
â”‚   â”œâ”€â”€ accuracy_f1_comparison.png
â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â”œâ”€â”€ ensemble_model.pkl
â”‚   â”œâ”€â”€ ensemble_results.json
â”‚   â”œâ”€â”€ fl_results.json
â”‚   â”œâ”€â”€ rl_best_model.pkl
â”‚   â”œâ”€â”€ rl_results.json
â”‚   â”œâ”€â”€ sa_results.json
â”‚   â”œâ”€â”€ evaluation_results.json
â”‚   â””â”€â”€ metrics_radar.png
â”‚
â”œâ”€â”€ DATASET_INFO.md
â”œâ”€â”€ HEART_FAILURE_DATASET_GUIDE.md
â”œâ”€â”€ SETUP_GUIDE.md
â””â”€â”€ package.json
````

---

## ğŸ§  Optimization Modules

### **1ï¸âƒ£ Simulated Annealing (SA)**
- Global stochastic search  
- Optimizes features & hyperparameters  
- Outputs â†’ `sa_results.json`, `sa_optimization.png`

---

### **2ï¸âƒ£ Reinforcement Learning (RL)**
- Learns optimal policy for model configs  
- Detects high-performing states through reward functions  
- Outputs â†’ `rl_best_model.pkl`, `rl_results.json`

---

### **3ï¸âƒ£ Federated Learning (FL)**
- Distributed training without centralizing data  
- Secure gradient-based updates  
- Outputs â†’ `fl_global_model.pkl`, `fl_results.json`

---

### **4ï¸âƒ£ Ensemble Optimization**
- Fuses SA + RL + FL models  
- Produces best generalizable performance  
- Outputs â†’ `ensemble_model.pkl`

---

## ğŸ“Š Compact Results (Clean View)

| Method | Accuracy | F1-Score | Summary |
|--------|----------|----------|---------|
| SA | ~93% | ~92% | Good global search |
| RL | ~95% | ~94% | Strong policy learning |
| FL | ~91% | ~90% | Robust distributed model |
| **Ensemble** | **99%** | **99%** | Best combined performance |

ğŸ¯ Full graphs available in `/output`.

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/aniborra5757/OptiFusion.git
cd OptiFusion
pip install -r requirements.txt
````

---

## â–¶ï¸ Running the Pipeline

```bash
python scripts/07_main_orchestration.py
```

This will:

* preprocess dataset
* run SA, RL, FL optimizers
* evaluate metrics
* generate visualizations
* save models & results

---

## ğŸ“˜ Documentation Files

* **SETUP_GUIDE.md** â€” Environment + execution guide
* **DATASET_INFO.md** â€” Source dataset details
* **HEART_FAILURE_DATASET_GUIDE.md** â€” Clinical feature explanation

---

## ğŸŒŸ Future Roadmap

* Privacy-preserving FedAvg + differential privacy
* Multi-agent RL for deeper optimization
* Interactive Streamlit UI for results exploration
* Support for more medical datasets
* MLOps-ready pipelines (CI/CD, automated evaluation)

---
## ğŸ‘¥ Team & Contributors

<p>
  <a href="https://github.com/aniborra5757"><img src="https://img.shields.io/badge/Ani%20(Lead)-GitHub-blue?style=for-the-badge&logo=github"></a>
  <a href="https://github.com/Manvitha1007"><img src="https://img.shields.io/badge/Manvitha-GitHub-blue?style=for-the-badge&logo=github"></a>
  <a href="https://github.com/QueenyVempa"><img src="https://img.shields.io/badge/Queeny%20Vempa-GitHub-blue?style=for-the-badge&logo=github"></a>
  <a href="https://github.com/varshini-1407"><img src="https://img.shields.io/badge/Varshini-GitHub-blue?style=for-the-badge&logo=github"></a>
</p>


<p align="center">
  <strong>âœ¨ OptiFusion â€” Optimizing the Future of Machine Learning âœ¨</strong>
</p>

